<!DOCTYPE html>
<html id="caseStudies" lang="ko" class="">
	<head>
		

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36037335-10');
</script>
<meta charset="utf-8">
<title>OpenAI Case Study - Kubernetes</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#326ce5">
<link rel="shortcut icon" type="image/png" href="/images/favicon.png">









<link rel="stylesheet" href="/css/style.b7b8403eb5b1fddd0a2da2a8383d5b53e6ef81c23e4b0e292e6103bd91f9502d.css" integrity="sha256-t7hAPrWx/d0KLaKoOD1bU&#43;bvgcI&#43;Sw4pLmEDvZH5UC0=">


<link rel="stylesheet" href="/css/base_fonts.css">
<link rel="stylesheet" href="/css/case-study-styles.css">
<link rel="stylesheet" href="/css/jquery-ui.min.css">
<link rel="stylesheet" href="/css/callouts.css">
<link rel="stylesheet" href="/css/custom-jekyll/tags.css">
<link rel="stylesheet" href="/css/style_case_studies.css">



<meta name="description" content="CASE STUDY:Launching and Scaling Up Experiments, Made Simple   Company &nbsp;OpenAI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location &nbsp;San Francisco, California&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Industry &nbsp;Artificial Intelligence Research   Challenge An artificial intelligence research lab, OpenAI needed infrastructure for deep learning that would allow experiments to be run either in the cloud or in its own data center, and to easily scale. Portability, speed, and cost were the main drivers. Solution OpenAI began running Kubernetes on top of AWS in 2016, and in early 2017 migrated to Azure.">
<meta property="og:description" content="CASE STUDY:Launching and Scaling Up Experiments, Made Simple   Company &nbsp;OpenAI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location &nbsp;San Francisco, California&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Industry &nbsp;Artificial Intelligence Research   Challenge An artificial intelligence research lab, OpenAI needed infrastructure for deep learning that would allow experiments to be run either in the cloud or in its own data center, and to easily scale. Portability, speed, and cost were the main drivers. Solution OpenAI began running Kubernetes on top of AWS in 2016, and in early 2017 migrated to Azure.">
<meta name="twitter:description" content="CASE STUDY:Launching and Scaling Up Experiments, Made Simple   Company &nbsp;OpenAI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location &nbsp;San Francisco, California&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Industry &nbsp;Artificial Intelligence Research   Challenge An artificial intelligence research lab, OpenAI needed infrastructure for deep learning that would allow experiments to be run either in the cloud or in its own data center, and to easily scale. Portability, speed, and cost were the main drivers. Solution OpenAI began running Kubernetes on top of AWS in 2016, and in early 2017 migrated to Azure.">
<meta property="og:url" content="https://kubernetes.io/ko/case-studies/openai/">
<meta property="og:title" content="OpenAI Case Study">
<meta name="twitter:title" content="OpenAI Case Study">
<meta name="twitter:image" content="https://kubernetes.io/images/favicon.png" />

<meta name="twitter:image:alt" content="Kubernetes">

<meta property="og:image" content="/images/kubernetes-horizontal-color.png">

<meta property="og:type" content="article">
<script src="/js/anchor-4.1.1.min.js"></script>
<script src="/js/jquery-3.2.1.min.js"></script>
<script src="/js/jquery-ui-1.12.1.min.js"></script>
<script src="/js/bootstrap-4.3.1.min.js"></script>
<script src="/js/sweetalert-2.1.2.min.js"></script>

<script src="/js/script.js"></script>
<script src="/js/custom-jekyll/tags.js"></script>


	</head>
	<body>
		<div id="cellophane" onclick="kub.toggleMenu()"></div>

<header>
    <a href="/ko/" class="logo" title="운영 수준의 컨테이너 오케스트레이션 - Kubernetes" aria-label="Kubernetes website"></a>

    <div class="nav-buttons" data-auto-burger="primary">
        <ul class="global-nav">
            
            
            <li><a href="/ko/docs/">문서</a></li>
            
            
            
            <li><a href="/ko/training/">교육</a></li>
            
            
            
            
            
            <li><a href="/ko/case-studies/" class="active">사례 연구</a></li>
            
            
            
             <li>
                <a href="#">
                    한국어 Korean <span class="ui-icon ui-icon-carat-1-s"></span>
                </a>
                <ul>
                
                    <li><a href="/case-studies/openai/">English</a></li>
                
                </ul>
            </li>

            <li>
                <a href="#">
                    v1.17 <span class="ui-icon ui-icon-carat-1-s"></span>
                </a>
                <ul>
                
                    <li><a href="https://kubernetes.io/ko/case-studies/openai/">v1.21</a></li>
                
                    <li><a href="https://v1-20.docs.kubernetes.io/ko/case-studies/openai/">v1.20</a></li>
                
                    <li><a href="https://v1-19.docs.kubernetes.io/ko/case-studies/openai/">v1.19</a></li>
                
                    <li><a href="https://v1-18.docs.kubernetes.io/ko/case-studies/openai/">v1.18</a></li>
                
                    <li><a href="https://v1-17.docs.kubernetes.io/ko/case-studies/openai/">v1.17</a></li>
                
                </ul>
            </li>
        </ul>
        
        <a href="/ko/docs/tutorials/kubernetes-basics/" class="button" id="tryKubernetes" data-auto-burger-exclude>쿠버네티스 기초 학습</a>
        

        <button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
    </div>

    <nav id="mainNav">
        <div class="main-section" data-auto-burger="primary">
         
           <div class="nav-box">
            <h3><a href="/ko/docs/tutorials/hello-minikube/">Get Started</a></h3>
           <p>Ready to get your hands dirty? Build a simple Kubernetes cluster that runs "Hello World" for Node.js.</p>

            </div>
         
           <div class="nav-box">
            <h3><a href="/ko/docs/home/">문서</a></h3>
           <p>개념, 튜토리얼 및 참조 문서와 함께 쿠버네티스 사용하는 방법을 익힐 수 있다. 또한, <a href="/editdocs/" data-auto-burger-exclude>문서에 기여하는 것도 도움을 줄 수 있다</a>!</p>

            </div>
         
        </div>
        <div class="main-section" data-auto-burger="primary">
            <div class="left">
                <h5 class="github-invite">코어 쿠버네티스 코드 베이스를 살펴보는데 관심이 있으십니까?</h5>
                <a href="https://github.com/kubernetes/kubernetes" class="button" data-auto-burger-exclude>GitHub에서 보기</a>
            </div>

            <div class="right">
                <h5 class="github-invite">커뮤니티 둘러보기</h5>
                <div class="social">
                    <a href="https://twitter.com/kubernetesio" class="twitter"><span>Twitter</span></a>
                    <a href="https://github.com/kubernetes/kubernetes" class="github"><span>GitHub</span></a>
                    <a href="http://slack.k8s.io/" class="slack"><span>Slack Slack</span></a>
                    <a href="https://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                    <a href="https://www.youtube.com/kubernetescommunity" class="youtube"><span>YouTube</span></a>
                    <a href="https://discuss.kubernetes.io" class="mailing-list"><span>Forum</span></a>
                    <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>이벤트 캘린더</span></a>
                </div>
            </div>
            <div class="clear" style="clear: both"></div>
        </div>
    </nav>
</header>

		

	
<div class="banner1 desktop" style="background-image: url('/images/CaseStudy_openAI_banner1.jpg')">
  <h1> CASE STUDY:<img src="/images/openAI_logo.png" style="margin-bottom:-1%" class="header_logo"><br> <div class="subhead">Launching and Scaling Up Experiments, Made Simple

</div></h1>

</div>

<div class="details">
    Company &nbsp;<b>OpenAI</b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location &nbsp;<b>San Francisco, California</b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Industry &nbsp;<b>Artificial Intelligence Research</b>
</div>

<hr>
<section class="section1">
<div class="cols">
  <div class="col1">
    <h2>Challenge</h2>
    An artificial intelligence research lab, OpenAI needed infrastructure for deep learning that would allow experiments to be run either in the cloud or in its own data center, and to easily scale. Portability, speed, and cost were the main drivers.
<br>
    <h2>Solution</h2>
    OpenAI began running Kubernetes on top of AWS in 2016, and in early 2017 migrated to Azure. OpenAI runs key experiments in fields including robotics and gaming both in Azure and in its own data centers, depending on which cluster has free capacity. "We use Kubernetes mainly as a batch scheduling system and rely on our <a href="https://github.com/openai/kubernetes-ec2-autoscaler">autoscaler</a> to dynamically scale up and down our cluster," says Christopher Berner, Head of Infrastructure. "This lets us significantly reduce costs for idle nodes, while still providing low latency and rapid iteration."
</div>

<div class="col2">

<h2>Impact</h2>
  The company has benefited from greater portability: "Because Kubernetes provides a consistent API, we can move our research experiments very easily between clusters," says Berner. Being able to use its own data centers when appropriate is "lowering costs and providing us access to hardware that we wouldn’t necessarily have access to in the cloud," he adds. "As long as the utilization is high, the costs are much lower there." Launching experiments also takes far less time: "One of our researchers who is working on a new distributed training system has been able to get his experiment running in two or three days. In a week or two he scaled it out to hundreds of GPUs. Previously, that would have easily been a couple of months of work."


</div>

</div>
</section>
<div class="banner2">
  <div class="banner2text">

<div class="video">
<iframe width="560" height="315" src="https://www.youtube.com/embed/v4N3Krzb8Eg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><br>
<span style="font-size:21px;line-height:0.5em !important;width:60%;">Check out "Building the Infrastructure that Powers the Future of AI" presented by  Vicki Cheung, Member of Technical Staff & Jonas Schneider, Member of Technical Staff at OpenAI from KubeCon/CloudNativeCon Europe 2017.</span>
</div>
  </div>
</div>
<section class="section2">
<div class="fullcol">
  <h2>From experiments in robotics to old-school video game play research, OpenAI’s work in artificial intelligence technology is meant to be shared.</h2>
  With a mission to ensure powerful AI systems are safe, OpenAI cares deeply about open source—both benefiting from it and contributing safety technology into it. "The research that we do, we want to spread it as widely as possible so everyone can benefit," says OpenAI’s Head of Infrastructure Christopher Berner. The lab’s philosophy—as well as its particular needs—lent itself to embracing an open source, cloud native strategy for its deep learning infrastructure.<br><br>
  OpenAI started running Kubernetes on top of AWS in 2016, and a year later, migrated the Kubernetes clusters to Azure. "We probably use Kubernetes differently from a lot of people," says Berner. "We use it for batch scheduling and as a workload manager for the cluster. It’s a way of coordinating a large number of containers that are all connected together. We rely on our <a href="https://github.com/openai/kubernetes-ec2-autoscaler">autoscaler</a> to dynamically scale up and down our cluster. This lets us significantly reduce costs for idle nodes, while still providing low latency and rapid iteration." <br><br>
  In the past year, Berner has overseen the launch of several Kubernetes clusters in OpenAI’s own data centers. "We run them in a hybrid model where the control planes—the Kubernetes API servers, <a href="https://github.com/coreos/etcd">etcd</a> and everything—are all in Azure, and then all of the Kubernetes nodes are in our own data center," says Berner. "The cloud is really convenient for managing etcd and all of the masters, and having backups and spinning up new nodes if anything breaks. This model allows us to take advantage of lower costs and have the availability of more specialized hardware in our own data center."


</div>
</section>
<div class="banner3" style="background-image: url('/images/CaseStudy_openAI_banner3.jpg')">
  <div class="banner3text">
    OpenAI’s experiments take advantage of Kubernetes’ benefits, including portability. "Because Kubernetes provides a consistent API, we can move our research experiments very easily between clusters..."

  </div>
</div>
<section class="section3">
<div class="fullcol">
  Different teams at OpenAI currently run a couple dozen projects. While the largest-scale workloads manage bare cloud VMs directly, most of OpenAI’s experiments take advantage of Kubernetes’ benefits, including portability. "Because Kubernetes provides a consistent API, we can move our research experiments very easily between clusters," says Berner. The on-prem clusters are generally "used for workloads where you need lots of GPUs, something like training an ImageNet model. Anything that’s CPU heavy, that’s run in the cloud. But we also have a number of teams that run their experiments both in Azure and in our own data centers, just depending on which cluster has free capacity, and that’s hugely valuable."<br><br>
  Berner has made the Kubernetes clusters available to all OpenAI teams to use if it’s a good fit. "I’ve worked a lot with our games team, which at the moment is doing research on classic console games," he says. "They had been running a bunch of their experiments on our dev servers, and they had been trying out Google cloud, managing their own VMs. We got them to try out our first on-prem Kubernetes cluster, and that was really successful. They’ve now moved over completely to it, and it has allowed them to scale up their experiments by 10x, and do that without needing to invest significant engineering time to figure out how to manage more machines. A lot of people are now following the same path."

</div>
</section>
<div class="banner4" style="background-image: url('/images/CaseStudy_openAI_banner4.jpg')">
  <div class="banner4text">
"One of our researchers who is working on a new distributed training system has been able to get his experiment running in two or three days," says Berner. "In a week or two he scaled it out to hundreds of GPUs. Previously, that would have easily been a couple of months of work."
  </div>
</div>

<section class="section5" style="padding:0px !important;">
<div class="fullcol">
  That path has been simplified by frameworks and tools that two of OpenAI’s teams have developed to handle interaction with Kubernetes. "You can just write some Python code, fill out a bit of configuration with exactly how many machines you need and which types, and then it will prepare all of those specifications and send it to the Kube cluster so that it gets launched there," says Berner. "And it also provides a bit of extra monitoring and better tooling that’s designed specifically for these machine learning projects."<br><br>
  The impact that Kubernetes has had at OpenAI is impressive. With Kubernetes, the frameworks and tooling, including the autoscaler, in place, launching experiments takes far less time. "One of our researchers who is working on a new distributed training system has been able to get his experiment running in two or three days," says Berner. "In a week or two he scaled it out to hundreds of GPUs. Previously, that would have easily been a couple of months of work."  <br><br>
  Plus, the flexibility they now have to use their on-prem Kubernetes cluster when appropriate is "lowering costs and providing us access to hardware that we wouldn’t necessarily have access to in the cloud," he says. "As long as the utilization is high, the costs are much lower in our data center. To an extent, you can also customize your hardware to exactly what you need."


</div>

<div class="banner5">
  <div class="banner5text">
    "Research teams can now take advantage of the frameworks we’ve built on top of Kubernetes, which make it easy to launch experiments, scale them by 10x or 50x, and take little effort to manage." <br><span style="font-size:14px;letter-spacing:0.12em;padding-top:20px">— CHRISTOPHER BERNER, HEAD OF INFRASTRUCTURE FOR OPENAI</span>
  </div>
</div>

<div class="fullcol">

  OpenAI is also benefiting from other technologies in the CNCF cloud-native ecosystem. <a href="https://grpc.io/">gRPC</a> is used by many of its systems for communications between different services, and <a href="https://prometheus.io/">Prometheus</a> is in place "as a debugging tool if things go wrong," says Berner. "We actually haven’t had any real problems in our Kubernetes clusters recently, so I don’t think anyone has looked at our Prometheus monitoring in a while. If something breaks, it will be there."<br><br>
  One of the things Berner continues to focus on is Kubernetes’ ability to scale, which is essential to deep learning experiments. OpenAI has been able to push one of its Kubernetes clusters on Azure up to more than <a href="https://blog.openai.com/scaling-kubernetes-to-2500-nodes/">2,500 nodes</a>. "I think we’ll probably hit the 5,000-machine number that Kubernetes has been tested at before too long," says Berner, adding, "We’re definitely <a href="https://jobs.lever.co/openai">hiring</a> if you’re excited about working on these things!"
</div>

</section>



		<footer>
    <div class="light-text main-section">
        <nav>
            
            
            
            <a href="/ko/docs/home/">홈</a>
            
            
            
            <a href="/ko/training/">교육</a>
            
            
            
            
            
            <a href="/ko/case-studies/">사례 연구</a>
            
        </nav>
        <div class="social" role="region" aria-label="Social hyperlinks">
            <div>
                <a href="https://twitter.com/kubernetesio" class="twitter"><span>Twitter</span></a>
                <a href="https://github.com/kubernetes/kubernetes" class="github"><span>GitHub</span></a>
                <a href="https://slack.k8s.io/" class="slack"><span>Slack</span></a>
            </div>
            <div>
                <a href="https://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                <a href="https://www.youtube.com/kubernetescommunity" class="youtube"><span>YouTube</span></a>
                <a href="https://discuss.kubernetes.io" class="mailing-list"><span>Forum</span></a>
                <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>이벤트 캘린더</span></a>
            </div>
            <div>
                
                <a href="https://git.k8s.io/community/contributors/guide" class="button">기여하기</a>
            </div>
        </div>
        <div class="miceType center">
            &copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a></a>
        </div>
        <div class="miceType center">
            Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">Trademark Usage page</a>
        </div>
        <div class="miceType center">
            ICP license: 京ICP备17074266号-3
        </div>
    </div>
</footer>

		<button class="flyout-button" onclick="kub.toggleToc()" aria-label="Toggle table of contents visibility"></button>

<script>

(function () {
    window.addEventListener('DOMContentLoaded', init)

        
        function init() {
            window.removeEventListener('DOMContentLoaded', init)
                hideNav()
        }

    function hideNav(toc){
        if (!toc) toc = document.querySelector('#docsToc')
        if (!toc) return
            var container = toc.querySelector('.container')

                
                if (container) {
                    if (container.childElementCount === 0 || toc.querySelectorAll('a.item').length === 1) {
                        toc.style.display = 'none'
                            document.getElementById('docsContent').style.width = '100%'
                    }
                } else {
                    requestAnimationFrame(function () {
                        hideNav(toc)
                    })
                }
    }
})();
</script>



	</body>
</html>