<!DOCTYPE html>
<html id="docs" lang="zh" class="">
	<head>
	

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36037335-10');
</script>
<meta charset="utf-8">
<title>配置资源不足时的处理方式 - Kubernetes</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#326ce5">
<link rel="shortcut icon" type="image/png" href="/images/favicon.png">









<link rel="stylesheet" href="/css/style.b7b8403eb5b1fddd0a2da2a8383d5b53e6ef81c23e4b0e292e6103bd91f9502d.css" integrity="sha256-t7hAPrWx/d0KLaKoOD1bU&#43;bvgcI&#43;Sw4pLmEDvZH5UC0=">


<link rel="stylesheet" href="/css/base_fonts.css">
<link rel="stylesheet" href="/css/jquery-ui.min.css">
<link rel="stylesheet" href="/css/callouts.css">
<link rel="stylesheet" href="/css/custom-jekyll/tags.css">



<meta name="description" content="">
<meta property="og:description" content="">
<meta name="twitter:description" content="">
<meta property="og:url" content="https://kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">
<meta property="og:title" content="配置资源不足时的处理方式">
<meta name="twitter:title" content="配置资源不足时的处理方式">
<meta name="twitter:image" content="https://kubernetes.io/images/favicon.png" />

<meta name="twitter:image:alt" content="Kubernetes">

<meta property="og:image" content="/images/kubernetes-horizontal-color.png">

<meta property="og:type" content="article">
<script src="/js/anchor-4.1.1.min.js"></script>
<script src="/js/jquery-3.2.1.min.js"></script>
<script src="/js/jquery-ui-1.12.1.min.js"></script>
<script src="/js/bootstrap-4.3.1.min.js"></script>
<script src="/js/sweetalert-2.1.2.min.js"></script>

<script src="/js/script.js"></script>
<script src="/js/custom-jekyll/tags.js"></script>


	</head>
	<body>
		<div id="cellophane" onclick="kub.toggleMenu()"></div>

<header>
    <a href="/zh/" class="logo" title="生产级别的容器编排系统 - Kubernetes" aria-label="Kubernetes website"></a>

    <div class="nav-buttons" data-auto-burger="primary">
        <ul class="global-nav">
            
            
            <li><a href="/zh/docs/" class="active">文档</a></li>
            
            <li><a href="/zh/blog/">博客</a></li>
            
            
            
            <li><a href="/zh/partners/">合作伙伴</a></li>
            
            <li><a href="/zh/community/">社区</a></li>
            
            <li><a href="/zh/case-studies/">案例分析</a></li>
            
            
            
             <li>
                <a href="#">
                    中文 Chinese <span class="ui-icon ui-icon-carat-1-s"></span>
                </a>
                <ul>
                
                    <li><a href="/docs/tasks/administer-cluster/out-of-resource/">English</a></li>
                
                </ul>
            </li>

            <li>
                <a href="#">
                    v1.17 <span class="ui-icon ui-icon-carat-1-s"></span>
                </a>
                <ul>
                
                    <li><a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">v1.21</a></li>
                
                    <li><a href="https://v1-20.docs.kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">v1.20</a></li>
                
                    <li><a href="https://v1-19.docs.kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">v1.19</a></li>
                
                    <li><a href="https://v1-18.docs.kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">v1.18</a></li>
                
                    <li><a href="https://v1-17.docs.kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource/">v1.17</a></li>
                
                </ul>
            </li>
        </ul>
        
        <a href="/zh/docs/tutorials/kubernetes-basics/" class="button" id="tryKubernetes" data-auto-burger-exclude>学习 Kubernetes 基础知识</a>
        

        <button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
    </div>

    <nav id="mainNav">
        <div class="main-section" data-auto-burger="primary">
         
           <div class="nav-box">
            <h3><a href="/zh/docs/tutorials/hello-minikube/">Get Started</a></h3>
           <p>Ready to get your hands dirty? Build a simple Kubernetes cluster that runs "Hello World" for Node.js.</p>

            </div>
         
           <div class="nav-box">
            <h3><a href="/zh/docs/home/">文档</a></h3>
           <p>通过演练，示例和参考文档了解如何使用 Kubernetes。你甚至可以<a href="/editdocs/" data-auto-burger-exclude>帮助贡献文档</a>！</p>

            </div>
         
           <div class="nav-box">
            <h3><a href="/zh/blog/">博客</a></h3>
           <p>阅读关于 kubernetes 和容器规范的最新信息,以及获取最新的技术。</p>

            </div>
         
        </div>
        <div class="main-section" data-auto-burger="primary">
            <div class="left">
                <h5 class="github-invite">想要修改 Kubernetes 的核心源代码？</h5>
                <a href="https://github.com/kubernetes/kubernetes" class="button" data-auto-burger-exclude>在 GitHub 上查看</a>
            </div>

            <div class="right">
                <h5 class="github-invite">了解社区</h5>
                <div class="social">
                    <a href="https://twitter.com/kubernetesio" class="twitter"><span>Twitter</span></a>
                    <a href="https://github.com/kubernetes/kubernetes" class="github"><span>GitHub</span></a>
                    <a href="http://slack.k8s.io/" class="slack"><span>Slack Slack</span></a>
                    <a href="https://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                    <a href="https://www.youtube.com/kubernetescommunity" class="youtube"><span>YouTube</span></a>
                    <a href="https://discuss.kubernetes.io" class="mailing-list"><span>论坛</span></a>
                    <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>事件日历</span></a>
                </div>
            </div>
            <div class="clear" style="clear: both"></div>
        </div>
    </nav>
</header>

		
		
		<section id="hero" class="light-text no-sub">
			











<h1>任务</h1>
<h5></h5>








<div id="vendorStrip" class="light-text">
	<ul>
		
		
		<li><a href="/zh/docs/home/">主页</a></li>
		
		
		<li><a href="/zh/docs/setup/">入门</a></li>
		
		
		<li><a href="/zh/docs/concepts/">概念</a></li>
		
		
		<li><a href="/zh/docs/tasks/" class="YAH">任务</a></li>
		
		
		<li><a href="/zh/docs/tutorials/">教程</a></li>
		
		
		<li><a href="/zh/docs/reference/">参考</a></li>
		
		
		<li><a href="/zh/docs/contribute/">贡献</a></li>
		
	</ul>
	<form id="searchBox" action="/docs/search/" role="search">
		<input type="text" id="search" name="q" placeholder="搜索" aria-label="Search">
	</form>
</div>

		</section>
		
    
		
<section id="deprecationWarning">
  <main>
    <div class="content deprecation-warning">
      <h3>
	 Kubernetes v1.17
	  版本的文档已不再维护。您现在看到的版本来自于一份静态的快照。如需查阅最新文档，请点击
	 <a href="https://kubernetes.io/docs/home/">最新版本。</a>
      </h3>
    </div>
  </main>
</section>


    <main>
        <section id="encyclopedia">
          
<div id="docsToc">
     <div class="pi-accordion">
    	
        
        
        
        
        
         
             
                 
             
         
             
                 
             
         
             
                 
             
         
             
                 
                          
                          
                 
             
         
             
         
             
         
             
         
         
        
        <a class="item" data-title="任务" href="/zh/docs/tasks/"></a>

	
	
			
			
			
			
			
		
	
	
	
		
			
<div class="item" data-title="安装工具">
	<div class="container">
		
		
		
		<a class="item" data-title="安装工具" href="/zh/docs/tasks/tools/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="安装并设置 kubectl" href="/zh/docs/tasks/tools/install-kubectl/"></a>

		
	
		
			

<a class="item" data-title="安装 Minikube" href="/zh/docs/tasks/tools/install-minikube/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="管理集群">
	<div class="container">
		
		
		
		<a class="item" data-title="管理集群" href="/zh/docs/tasks/administer-cluster/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			
<div class="item" data-title="用 kubeadm 进行管理">
	<div class="container">
		
		
		
		<a class="item" data-title="用 kubeadm 进行管理" href="/zh/docs/tasks/administer-cluster/kubeadm/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="使用 kubeadm 进行证书管理" href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/"></a>

		
	
		
			

<a class="item" data-title="升级 kubeadm 集群" href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="管理内存，CPU 和 API 资源">
	<div class="container">
		
		
		
		<a class="item" data-title="管理内存，CPU 和 API 资源" href="/zh/docs/tasks/administer-cluster/manage-resources/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="为命名空间配置默认的内存请求和限制" href="/zh/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/"></a>

		
	
		
			

<a class="item" data-title="为命名空间配置默认的CPU请求和限制" href="/zh/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/"></a>

		
	
		
			

<a class="item" data-title="配置命名空间的最小和最大内存约束" href="/zh/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/"></a>

		
	
		
			

<a class="item" data-title="为命名空间配置CPU最小和最大限制" href="/zh/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/"></a>

		
	
		
			

<a class="item" data-title="为命名空间配置内存和 CPU 配额" href="/zh/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/"></a>

		
	
		
			

<a class="item" data-title="配置命名空间下pod总数" href="/zh/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="Install a Network Policy Provider">
	<div class="container">
		
		
		
		<a class="item" data-title="Install a Network Policy Provider" href="/zh/docs/tasks/administer-cluster/network-policy-provider/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="使用 Calico 作为 NetworkPolicy" href="/zh/docs/tasks/administer-cluster/network-policy-provider/calico-network-policy/"></a>

		
	
		
			

<a class="item" data-title="使用 Cilium 作为 NetworkPolicy" href="/zh/docs/tasks/administer-cluster/network-policy-provider/cilium-network-policy/"></a>

		
	
		
			

<a class="item" data-title="使用 Kube-router 作为 NetworkPolicy" href="/zh/docs/tasks/administer-cluster/network-policy-provider/kube-router-network-policy/"></a>

		
	
		
			

<a class="item" data-title="使用 Romana 作为 NetworkPolicy" href="/zh/docs/tasks/administer-cluster/network-policy-provider/romana-network-policy/"></a>

		
	
		
			

<a class="item" data-title="使用 Weave Net 作为 NetworkPolicy" href="/zh/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/"></a>

		
	

	</div>
</div>

		
	
		
			

<a class="item" data-title="Debug DNS 方案" href="/zh/docs/tasks/administer-cluster/dns-debugging-resolution/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Enabling Service Topology <small>(EN)</small>" href="/docs/tasks/administer-cluster/enabling-service-topology/"></a>

		
	
		
			

<a class="item" data-title="IP Masquerade Agent 用户指南" href="/zh/docs/tasks/administer-cluster/ip-masq-agent/"></a>

		
	
		
			

<a class="item" data-title="Kubernetes 云管理控制器" href="/zh/docs/tasks/administer-cluster/running-cloud-controller/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Safely Drain a Node while Respecting the PodDisruptionBudget <small>(EN)</small>" href="/docs/tasks/administer-cluster/safely-drain-node/"></a>

		
	
		
			

<a class="item" data-title="为 Kubernetes 运行 etcd 集群" href="/zh/docs/tasks/administer-cluster/configure-upgrade-etcd/"></a>

		
	
		
			

<a class="item" data-title="为系统守护进程预留计算资源" href="/zh/docs/tasks/administer-cluster/reserve-compute-resources/"></a>

		
	
		
			

<a class="item" data-title="为节点发布扩展资源" href="/zh/docs/tasks/administer-cluster/extended-resource-node/"></a>

		
	
		
			

<a class="item" data-title="使用 CoreDNS 进行服务发现" href="/zh/docs/tasks/administer-cluster/coredns/"></a>

		
	
		
			

<a class="item" data-title="使用 KMS 提供商进行数据加密" href="/zh/docs/tasks/administer-cluster/kms-provider/"></a>

		
	
		
			

<a class="item" data-title="使用 Kubernetes API 访问集群" href="/zh/docs/tasks/administer-cluster/access-cluster-api/"></a>

		
	
		
			

<a class="item" data-title="关键插件 Pod 的调度保证" href="/zh/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/"></a>

		
	
		
			

<a class="item" data-title="启用端点切片" href="/zh/docs/tasks/administer-cluster/enabling-endpointslices/"></a>

		
	
		
			

<a class="item" data-title="命名空间演练" href="/zh/docs/tasks/administer-cluster/namespaces-walkthrough/"></a>

		
	
		
			

<a class="item" data-title="在 Kubernetes 集群中使用 NodeLocal DNSCache" href="/zh/docs/tasks/administer-cluster/nodelocaldns/"></a>

		
	
		
			

<a class="item" data-title="在 Kubernetes 集群中使用 sysctl" href="/zh/docs/tasks/administer-cluster/sysctl-cluster/"></a>

		
	
		
			

<a class="item" data-title="在实时集群上重新配置节点的 Kubelet" href="/zh/docs/tasks/administer-cluster/reconfigure-kubelet/"></a>

		
	
		
			

<a class="item" data-title="声明网络策略" href="/zh/docs/tasks/administer-cluster/declare-network-policy/"></a>

		
	
		
			

<a class="item" data-title="开发云控制器管理器" href="/zh/docs/tasks/administer-cluster/developing-cloud-controller-manager/"></a>

		
	
		
			

<a class="item" data-title="控制节点上的 CPU 管理策略" href="/zh/docs/tasks/administer-cluster/cpu-management-policies/"></a>

		
	
		
			

<a class="item" data-title="控制节点上的拓扑管理策略" href="/zh/docs/tasks/administer-cluster/topology-manager/"></a>

		
	
		
			

<a class="item" data-title="搭建高可用的 Kubernetes Masters" href="/zh/docs/tasks/administer-cluster/highly-available-master/"></a>

		
	
		
			

<a class="item" data-title="改变默认 StorageClass" href="/zh/docs/tasks/administer-cluster/change-default-storage-class/"></a>

		
	
		
			

<a class="item" data-title="更改 PersistentVolume 的回收策略" href="/zh/docs/tasks/administer-cluster/change-pv-reclaim-policy/"></a>

		
	
		
			

<a class="item" data-title="自定义 DNS 服务" href="/zh/docs/tasks/administer-cluster/dns-custom-nameservers/"></a>

		
	
		
			

<a class="item" data-title="访问集群上运行的服务" href="/zh/docs/tasks/administer-cluster/access-cluster-services/"></a>

		
	
		
			

<a class="item" data-title="通过命名空间共享集群" href="/zh/docs/tasks/administer-cluster/namespaces/"></a>

		
	
		
			

<a class="item" data-title="通过配置文件设置 Kubelet 参数" href="/zh/docs/tasks/administer-cluster/kubelet-config-file/"></a>

		
	
		
			

<a class="item" data-title="配置 API 对象配额" href="/zh/docs/tasks/administer-cluster/quota-api-object/"></a>

		
	
		
			

<a class="item" data-title="配置多个调度器" href="/zh/docs/tasks/administer-cluster/configure-multiple-schedulers/"></a>

		
	
		
			

<a class="item" data-title="配置资源不足时的处理方式" href="/zh/docs/tasks/administer-cluster/out-of-resource/"></a>

		
	
		
			

<a class="item" data-title="限制存储消耗" href="/zh/docs/tasks/administer-cluster/limit-storage-consumption/"></a>

		
	
		
			

<a class="item" data-title="集群 DNS 服务自动伸缩" href="/zh/docs/tasks/administer-cluster/dns-horizontal-autoscaling/"></a>

		
	
		
			

<a class="item" data-title="集群安全" href="/zh/docs/tasks/administer-cluster/securing-a-cluster/"></a>

		
	
		
			

<a class="item" data-title="集群管理" href="/zh/docs/tasks/administer-cluster/cluster-management/"></a>

		
	
		
			

<a class="item" data-title="静态加密 Secret 数据" href="/zh/docs/tasks/administer-cluster/encrypt-data/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="配置 Pods 和容器">
	<div class="container">
		
		
		
		<a class="item" data-title="配置 Pods 和容器" href="/zh/docs/tasks/configure-pod-container/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="为容器和 Pod 分配内存资源" href="/zh/docs/tasks/configure-pod-container/assign-memory-resource/"></a>

		
	
		
			

<a class="item" data-title="Assign CPU Resources to Containers and Pods" href="/zh/docs/tasks/configure-pod-container/assign-cpu-resource/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Configure GMSA for Windows Pods and containers <small>(EN)</small>" href="/docs/tasks/configure-pod-container/configure-gmsa/"></a>

		
	
		
			

<a class="item" data-title="为 Windows 的 pod 和容器配置 RunAsUserName" href="/zh/docs/tasks/configure-pod-container/configure-runasusername/"></a>

		
	
		
			

<a class="item" data-title="配置 Pod 的服务质量" href="/zh/docs/tasks/configure-pod-container/quality-service-pod/"></a>

		
	
		
			

<a class="item" data-title="为容器分派扩展资源" href="/zh/docs/tasks/configure-pod-container/extended-resource/"></a>

		
	
		
			

<a class="item" data-title="配置 Pod 以使用卷进行存储" href="/zh/docs/tasks/configure-pod-container/configure-volume-storage/"></a>

		
	
		
			

<a class="item" data-title="配置 Pod 以使用 PersistentVolume 作为存储" href="/zh/docs/tasks/configure-pod-container/configure-persistent-volume-storage/"></a>

		
	
		
			

<a class="item" data-title="配置 Pod 使用投射卷作存储" href="/zh/docs/tasks/configure-pod-container/configure-projected-volume-storage/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Configure a Security Context for a Pod or Container <small>(EN)</small>" href="/docs/tasks/configure-pod-container/security-context/"></a>

		
	
		
			

<a class="item" data-title="为 Pod 配置服务账户" href="/zh/docs/tasks/configure-pod-container/configure-service-account/"></a>

		
	
		
			

<a class="item" data-title="从私有仓库拉取镜像" href="/zh/docs/tasks/configure-pod-container/pull-image-private-registry/"></a>

		
	
		
			

<a class="item" data-title="配置存活、就绪和启动探测器" href="/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"></a>

		
	
		
			

<a class="item" data-title="将 Pod 分配给节点" href="/zh/docs/tasks/configure-pod-container/assign-pods-nodes/"></a>

		
	
		
			

<a class="item" data-title="配置 Pod 初始化" href="/zh/docs/tasks/configure-pod-container/configure-pod-initialization/"></a>

		
	
		
			

<a class="item" data-title="为容器的生命周期事件设置处理函数" href="/zh/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/"></a>

		
	
		
			

<a class="item" data-title="使用 ConfigMap 配置 Pod" href="/zh/docs/tasks/configure-pod-container/configure-pod-configmap/"></a>

		
	
		
			

<a class="item" data-title="在 Pod 中的容器之间共享进程命名空间" href="/zh/docs/tasks/configure-pod-container/share-process-namespace/"></a>

		
	
		
			

<a class="item" data-title="创建静态 Pod" href="/zh/docs/tasks/configure-pod-container/static-pod/"></a>

		
	
		
			

<a class="item" data-title="将 Docker Compose 文件转换为 Kubernetes 资源" href="/zh/docs/tasks/configure-pod-container/translate-compose-kubernetes/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="管理 Kubernetes 对象">
	<div class="container">
		
		
		
		<a class="item" data-title="管理 Kubernetes 对象" href="/zh/docs/tasks/manage-kubernetes-objects/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" target="_blank" data-title="Declarative Management of Kubernetes Objects Using Configuration Files <small>(EN)</small>" href="/docs/tasks/manage-kubernetes-objects/declarative-config/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Declarative Management of Kubernetes Objects Using Kustomize <small>(EN)</small>" href="/docs/tasks/manage-kubernetes-objects/kustomization/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Managing Kubernetes Objects Using Imperative Commands <small>(EN)</small>" href="/docs/tasks/manage-kubernetes-objects/imperative-command/"></a>

		
	
		
			

<a class="item" data-title="使用配置文件对 Kubernetes 对象进行命令式管理" href="/zh/docs/tasks/manage-kubernetes-objects/imperative-config/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="给应用注入数据">
	<div class="container">
		
		
		
		<a class="item" data-title="给应用注入数据" href="/zh/docs/tasks/inject-data-application/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="为容器设置启动时要执行的命令及其入参" href="/zh/docs/tasks/inject-data-application/define-command-argument-container/"></a>

		
	
		
			

<a class="item" data-title="为容器设置环境变量" href="/zh/docs/tasks/inject-data-application/define-environment-variable-container/"></a>

		
	
		
			

<a class="item" data-title="使用 PodPreset 将信息注入 Pods" href="/zh/docs/tasks/inject-data-application/podpreset/"></a>

		
	
		
			

<a class="item" data-title="使用 Secret 安全地分发凭证" href="/zh/docs/tasks/inject-data-application/distribute-credentials-secure/"></a>

		
	
		
			

<a class="item" data-title="通过文件将Pod信息呈现给容器" href="/zh/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/"></a>

		
	
		
			

<a class="item" data-title="通过环境变量将Pod信息呈现给容器" href="/zh/docs/tasks/inject-data-application/environment-variable-expose-pod-information/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="运行应用">
	<div class="container">
		
		
		
		<a class="item" data-title="运行应用" href="/zh/docs/tasks/run-application/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="运行一个有状态的应用程序" href="/zh/docs/tasks/run-application/run-replicated-stateful-application/"></a>

		
	
		
			

<a class="item" data-title="使用 kubectl patch 更新 API 对象" href="/zh/docs/tasks/run-application/update-api-object-kubectl-patch/"></a>

		
	
		
			

<a class="item" data-title="删除 StatefulSet" href="/zh/docs/tasks/run-application/delete-stateful-set/"></a>

		
	
		
			

<a class="item" data-title="强制删除 StatefulSet 类型的 Pods" href="/zh/docs/tasks/run-application/force-delete-stateful-set-pod/"></a>

		
	
		
			

<a class="item" data-title="基于Replication Controller执行滚动升级" href="/zh/docs/tasks/run-application/rolling-update-replication-controller/"></a>

		
	
		
			

<a class="item" data-title="Pod 水平自动伸缩" href="/zh/docs/tasks/run-application/horizontal-pod-autoscale/"></a>

		
	
		
			

<a class="item" data-title="Horizontal Pod Autoscaler演练" href="/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/"></a>

		
	
		
			

<a class="item" data-title="指定应用程序的中断预算（Disruption Budget）" href="/zh/docs/tasks/run-application/configure-pdb/"></a>

		
	
		
			

<a class="item" data-title="使用Deployment运行一个无状态应用" href="/zh/docs/tasks/run-application/run-stateless-application-deployment/"></a>

		
	
		
			

<a class="item" data-title="弹缩StatefulSet" href="/zh/docs/tasks/run-application/scale-stateful-set/"></a>

		
	
		
			

<a class="item" data-title="运行一个单实例有状态应用" href="/zh/docs/tasks/run-application/run-single-instance-stateful-application/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="运行 Jobs">
	<div class="container">
		
		
		
		<a class="item" data-title="运行 Jobs" href="/zh/docs/tasks/job/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="使用 CronJob 运行自动化任务" href="/zh/docs/tasks/job/automated-tasks-with-cron-jobs/"></a>

		
	
		
			

<a class="item" data-title="使用扩展进行并行处理" href="/zh/docs/tasks/job/parallel-processing-expansion/"></a>

		
	
		
			

<a class="item" data-title="使用工作队列进行粗粒度并行处理" href="/zh/docs/tasks/job/coarse-parallel-processing-work-queue/"></a>

		
	
		
			

<a class="item" data-title="使用工作队列进行精细的并行处理" href="/zh/docs/tasks/job/fine-parallel-processing-work-queue/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="访问集群中的应用程序">
	<div class="container">
		
		
		
		<a class="item" data-title="访问集群中的应用程序" href="/zh/docs/tasks/access-application-cluster/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="网页界面 (Dashboard)" href="/zh/docs/tasks/access-application-cluster/web-ui-dashboard/"></a>

		
	
		
			

<a class="item" data-title="访问集群" href="/zh/docs/tasks/access-application-cluster/access-cluster/"></a>

		
	
		
			

<a class="item" data-title="使用端口转发来访问集群中的应用" href="/zh/docs/tasks/access-application-cluster/port-forward-access-application-cluster/"></a>

		
	
		
			

<a class="item" data-title="使用服务来访问集群中的应用" href="/zh/docs/tasks/access-application-cluster/service-access-application-cluster/"></a>

		
	
		
			

<a class="item" data-title="创建一个外部负载均衡器" href="/zh/docs/tasks/access-application-cluster/create-external-load-balancer/"></a>

		
	
		
			

<a class="item" data-title="配置你的云平台防火墙" href="/zh/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Set up Ingress on Minikube with the NGINX Ingress Controller <small>(EN)</small>" href="/docs/tasks/access-application-cluster/ingress-minikube/"></a>

		
	
		
			

<a class="item" data-title="列出集群中所有运行容器的镜像" href="/zh/docs/tasks/access-application-cluster/list-all-running-container-images/"></a>

		
	
		
			

<a class="item" data-title="为集群配置 DNS" href="/zh/docs/tasks/access-application-cluster/configure-dns-cluster/"></a>

		
	
		
			

<a class="item" data-title="使用 Service 把前端连接到后端" href="/zh/docs/tasks/access-application-cluster/connecting-frontend-backend/"></a>

		
	
		
			

<a class="item" data-title="同 Pod 内的容器使用共享卷通信" href="/zh/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/"></a>

		
	
		
			

<a class="item" data-title="配置对多集群的访问" href="/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="监控、日志和排错">
	<div class="container">
		
		
		
		<a class="item" data-title="监控、日志和排错" href="/zh/docs/tasks/debug-application-cluster/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="Auditing" href="/zh/docs/tasks/debug-application-cluster/audit/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Auditing with Falco <small>(EN)</small>" href="/docs/tasks/debug-application-cluster/falco/"></a>

		
	
		
			

<a class="item" target="_blank" data-title="Logging Using Stackdriver <small>(EN)</small>" href="/docs/tasks/debug-application-cluster/logging-stackdriver/"></a>

		
	
		
			

<a class="item" data-title="StackDriver 中的事件" href="/zh/docs/tasks/debug-application-cluster/events-stackdriver/"></a>

		
	
		
			

<a class="item" data-title="使用 crictl 对 Kubernetes 节点进行调试" href="/zh/docs/tasks/debug-application-cluster/crictl/"></a>

		
	
		
			

<a class="item" data-title="使用 ElasticSearch 和 Kibana 进行日志管理" href="/zh/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/"></a>

		
	
		
			

<a class="item" data-title="在本地开发和调试服务" href="/zh/docs/tasks/debug-application-cluster/local-debugging/"></a>

		
	
		
			

<a class="item" data-title="应用故障排查" href="/zh/docs/tasks/debug-application-cluster/debug-application/"></a>

		
	
		
			

<a class="item" data-title="应用自测与调试" href="/zh/docs/tasks/debug-application-cluster/debug-application-introspection/"></a>

		
	
		
			

<a class="item" data-title="排错" href="/zh/docs/tasks/debug-application-cluster/troubleshooting/"></a>

		
	
		
			

<a class="item" data-title="确定 Pod 失败的原因" href="/zh/docs/tasks/debug-application-cluster/determine-reason-pod-failure/"></a>

		
	
		
			

<a class="item" data-title="节点健康监测" href="/zh/docs/tasks/debug-application-cluster/monitor-node-health/"></a>

		
	
		
			

<a class="item" data-title="获取正在运行容器的 Shell" href="/zh/docs/tasks/debug-application-cluster/get-shell-running-container/"></a>

		
	
		
			

<a class="item" data-title="调试 Init 容器" href="/zh/docs/tasks/debug-application-cluster/debug-init-containers/"></a>

		
	
		
			

<a class="item" data-title="调试 Pods 和 Replication Controllers" href="/zh/docs/tasks/debug-application-cluster/debug-pod-replication-controller/"></a>

		
	
		
			

<a class="item" data-title="调试 Service" href="/zh/docs/tasks/debug-application-cluster/debug-service/"></a>

		
	
		
			

<a class="item" data-title="调试StatefulSet" href="/zh/docs/tasks/debug-application-cluster/debug-stateful-set/"></a>

		
	
		
			

<a class="item" data-title="资源指标管道" href="/zh/docs/tasks/debug-application-cluster/resource-metrics-pipeline/"></a>

		
	
		
			

<a class="item" data-title="资源监控工具" href="/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/"></a>

		
	
		
			

<a class="item" data-title="集群故障排查" href="/zh/docs/tasks/debug-application-cluster/debug-cluster/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="扩展 Kubernetes">
	<div class="container">
		
		
		
		<a class="item" data-title="扩展 Kubernetes" href="/zh/docs/tasks/access-kubernetes-api/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			
<div class="item" data-title="使用自定义资源">
	<div class="container">
		
		
		
		<a class="item" data-title="使用自定义资源" href="/zh/docs/tasks/access-kubernetes-api/custom-resources/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" target="_blank" data-title="Extend the Kubernetes API with CustomResourceDefinitions <small>(EN)</small>" href="/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/"></a>

		
	
		
			

<a class="item" data-title="用户自定义资源版本" href="/zh/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definition-versioning/"></a>

		
	

	</div>
</div>

		
	
		
			

<a class="item" data-title="配置聚合层" href="/zh/docs/tasks/access-kubernetes-api/configure-aggregation-layer/"></a>

		
	
		
			

<a class="item" data-title="设置一个扩展的 API server" href="/zh/docs/tasks/access-kubernetes-api/setup-extension-api-server/"></a>

		
	
		
			

<a class="item" data-title="使用 HTTP 代理访问 Kubernetes API" href="/zh/docs/tasks/access-kubernetes-api/http-proxy-access-api/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="TLS">
	<div class="container">
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="管理集群中的 TLS 认证" href="/zh/docs/tasks/tls/managing-tls-in-a-cluster/"></a>

		
	
		
			

<a class="item" data-title="证书轮换" href="/zh/docs/tasks/tls/certificate-rotation/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="联邦 - 在多个集群上运行一个应用">
	<div class="container">
		
		
		
		<a class="item" data-title="联邦 - 在多个集群上运行一个应用" href="/zh/docs/tasks/federation/"></a>
		
		
	
	
			
			
		
	
	
	
		
			

<a class="item" data-title="将 CoreDNS 设置为联邦集群的 DNS 提供者" href="/zh/docs/tasks/federation/set-up-coredns-provider-federation/"></a>

		
	
		
			

<a class="item" data-title="使用联合服务来实现跨集群的服务发现" href="/zh/docs/tasks/federation/federation-service-discovery/"></a>

		
	
		
			
<div class="item" data-title="管理联邦控制平面">
	<div class="container">
		
		
		
		<a class="item" data-title="管理联邦控制平面" href="/zh/docs/tasks/federation/administer-federation/"></a>
		
		
	
	
			
			
		
	
	
	
		
			

<a class="item" data-title="联邦 ConfigMap" href="/zh/docs/tasks/federation/administer-federation/configmap/"></a>

		
	
		
			

<a class="item" data-title="联邦 DaemonSet" href="/zh/docs/tasks/federation/administer-federation/daemonset/"></a>

		
	
		
			

<a class="item" data-title="联邦 Deployment" href="/zh/docs/tasks/federation/administer-federation/deployment/"></a>

		
	
		
			

<a class="item" data-title="联邦 Job" href="/zh/docs/tasks/federation/administer-federation/job/"></a>

		
	
		
			

<a class="item" data-title="联邦 ReplicaSet" href="/zh/docs/tasks/federation/administer-federation/replicaset/"></a>

		
	
		
			

<a class="item" data-title="联邦 Secret" href="/zh/docs/tasks/federation/administer-federation/secret/"></a>

		
	
		
			

<a class="item" data-title="联邦事件" href="/zh/docs/tasks/federation/administer-federation/events/"></a>

		
	
		
			

<a class="item" data-title="联邦命名空间" href="/zh/docs/tasks/federation/administer-federation/namespaces/"></a>

		
	

	</div>
</div>

		
	
		
			

<a class="item" data-title="在联邦中设置放置策略" href="/zh/docs/tasks/federation/set-up-placement-policies-federation/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="管理集群守护进程">
	<div class="container">
		
		
		
		<a class="item" data-title="管理集群守护进程" href="/zh/docs/tasks/manage-daemon/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="对 DaemonSet 执行回滚" href="/zh/docs/tasks/manage-daemon/rollback-daemon-set/"></a>

		
	
		
			

<a class="item" data-title="对 DaemonSet 执行滚动更新" href="/zh/docs/tasks/manage-daemon/update-daemon-set/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="安装服务目录">
	<div class="container">
		
		
		
		<a class="item" data-title="安装服务目录" href="/zh/docs/tasks/service-catalog/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="使用 Helm 安装 Service Catalog" href="/zh/docs/tasks/service-catalog/install-service-catalog-using-helm/"></a>

		
	
		
			

<a class="item" data-title="使用 SC 安装服务目录" href="/zh/docs/tasks/service-catalog/install-service-catalog-using-sc/"></a>

		
	

	</div>
</div>

		
	
		
			
<div class="item" data-title="网络">
	<div class="container">
		
		
		
		<a class="item" data-title="网络" href="/zh/docs/tasks/network/"></a>
		
		
	
	
			
			
			
			
			
		
	
	
	
		
			

<a class="item" data-title="验证 IPv4/IPv6 双协议栈" href="/zh/docs/tasks/network/validate-dual-stack/"></a>

		
	

	</div>
</div>

		
	
		
			

<a class="item" data-title="用插件扩展 kubectl" href="/zh/docs/tasks/extend-kubectl/kubectl-plugins/"></a>

		
	
		
			

<a class="item" data-title="管理巨页（HugePages）" href="/zh/docs/tasks/manage-hugepages/scheduling-hugepages/"></a>

		
	
		
			

<a class="item" data-title="调度 GPUs" href="/zh/docs/tasks/manage-gpus/scheduling-gpus/"></a>

		
	





     </div> 
    <button class="push-menu-close-button" onclick="kub.toggleToc()"></button>
</div> 


          <div id="docsContent">
            

<p>
  <a href="https://github.com/kubernetes/website/edit/master/content/zh/docs/tasks/administer-cluster/out-of-resource.md" id="editPageButton" target="_blank">
    Edit This Page
  </a>
</p>

<h1>配置资源不足时的处理方式</h1>



<!--
This page explains how to configure out of resource handling with `kubelet`.

The `kubelet` needs to preserve node stability when available compute resources
are low. This is especially important when dealing with incompressible
compute resources, such as memory or disk space. If such resources are exhausted,
nodes become unstable.
-->

<p>本页介绍了如何使用<code>kubelet</code>配置资源不足时的处理方式。</p>

<p>当可用计算资源较少时，<code>kubelet</code>需要保证节点稳定性。这在处理如内存和硬盘之类的不可压缩资源时尤为重要。如果任意一种资源耗尽，节点将会变得不稳定。</p>









<ul id="markdown-toc">










<li><a href="#%e9%a9%b1%e9%80%90%e7%ad%96%e7%95%a5">驱逐策略</a></li>




<li><a href="#%e8%8a%82%e7%82%b9-oom-%e8%a1%8c%e4%b8%ba">节点 OOM 行为</a></li>




<li><a href="#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5">最佳实践</a></li>




<li><a href="#%e5%bc%83%e7%94%a8%e7%8e%b0%e6%9c%89%e7%89%b9%e6%80%a7%e6%a0%87%e7%ad%be%e4%bb%a5%e5%9b%9e%e6%94%b6%e7%a3%81%e7%9b%98">弃用现有特性标签以回收磁盘</a></li>




<li><a href="#%e5%b7%b2%e7%9f%a5%e9%97%ae%e9%a2%98">已知问题</a></li>



















</ul>


<!--
## Eviction Policy

The `kubelet` can proactively monitor for and prevent total starvation of a
compute resource. In those cases, the `kubelet` can reclaim the starved
resource by proactively failing one or more Pods. When the `kubelet` fails
a Pod, it terminates all of its containers and transitions its `PodPhase` to `Failed`.

If the evicted Pod is managed by a Deployment, the Deployment will create another Pod 
to be scheduled by Kubernetes.

-->

<h2 id="驱逐策略">驱逐策略</h2>

<p><code>kubelet</code> 能够主动监测和防止计算资源的全面短缺。在那种情况下，<code>kubelet</code>可以主动地结束一个或多个 pod 以回收短缺的资源。当 <code>kubelet</code> 结束一个 pod 时，它将终止 pod 中的所有容器，而 pod 的 <code>PodPhase</code> 将变为 <code>Failed</code>。</p>

<p>如果被驱逐的 Pod 由 Deployment 管理，这个 Deployment 会创建另一个 Pod 给 Kubernetes 来调度。</p>

<!--
### Eviction Signals

The `kubelet` supports eviction decisions based on the signals described in the following
table. The value of each signal is described in the Description column, which is based on
the `kubelet` summary API.

| Eviction Signal  | Description                                                                     |
|----------------------------|-----------------------------------------------------------------------|
| `memory.available` | `memory.available` := `node.status.capacity[memory]` - `node.stats.memory.workingSet` |
| `nodefs.available` | `nodefs.available` := `node.stats.fs.available` |
| `nodefs.inodesFree` | `nodefs.inodesFree` := `node.stats.fs.inodesFree` |
| `imagefs.available` | `imagefs.available` := `node.stats.runtime.imagefs.available` |
| `imagefs.inodesFree` | `imagefs.inodesFree` := `node.stats.runtime.imagefs.inodesFree` |

Each of the above signals supports either a literal or percentage based value.
The percentage based value is calculated relative to the total capacity
associated with each signal.

The value for `memory.available` is derived from the cgroupfs instead of tools
like `free -m`. This is important because `free -m` does not work in a
container, and if users use the [node
allocatable](/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable) feature, out of resource decisions
are made local to the end user Pod part of the cgroup hierarchy as well as the
root node. This
[script](/docs/tasks/administer-cluster/out-of-resource/memory-available.sh)
reproduces the same set of steps that the `kubelet` performs to calculate
`memory.available`. The `kubelet` excludes inactive_file (i.e. # of bytes of
file-backed memory on inactive LRU list) from its calculation as it assumes that
memory is reclaimable under pressure.

`kubelet` supports only two filesystem partitions.

1. The `nodefs` filesystem that kubelet uses for volumes, daemon logs, etc.
2. The `imagefs` filesystem that container runtimes uses for storing images and
   container writable layers.

`imagefs` is optional. `kubelet` auto-discovers these filesystems using
cAdvisor. `kubelet` does not care about any other filesystems. Any other types
of configurations are not currently supported by the kubelet. For example, it is
*not OK* to store volumes and logs in a dedicated `filesystem`.

In future releases, the `kubelet` will deprecate the existing [garbage
collection](/docs/concepts/cluster-administration/kubelet-garbage-collection/)
support in favor of eviction in response to disk pressure.
-->

<h3 id="驱逐信号">驱逐信号</h3>

<p><code>kubelet</code> 支持按照以下表格中描述的信号触发驱逐决定。每个信号的值在 description 列描述，基于 <code>kubelet</code> 摘要 API。</p>

<table>
<thead>
<tr>
<th>驱逐信号</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>memory.available</code></td>
<td><code>memory.available</code> := <code>node.status.capacity[memory]</code> - <code>node.stats.memory.workingSet</code></td>
</tr>

<tr>
<td><code>nodefs.available</code></td>
<td><code>nodefs.available</code> := <code>node.stats.fs.available</code></td>
</tr>

<tr>
<td><code>nodefs.inodesFree</code></td>
<td><code>nodefs.inodesFree</code> := <code>node.stats.fs.inodesFree</code></td>
</tr>

<tr>
<td><code>imagefs.available</code></td>
<td><code>imagefs.available</code> := <code>node.stats.runtime.imagefs.available</code></td>
</tr>

<tr>
<td><code>imagefs.inodesFree</code></td>
<td><code>imagefs.inodesFree</code> := <code>node.stats.runtime.imagefs.inodesFree</code></td>
</tr>
</tbody>
</table>

<p>上面的每个信号都支持字面值或百分比的值。基于百分比的值的计算与每个信号对应的总容量相关。</p>

<p><code>memory.available</code> 的值从 cgroupfs 获取，而不是通过类似 <code>free -m</code> 的工具。这很重要，因为 <code>free -m</code> 不能在容器中工作，并且如果用户使用了 <a href="/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable">可分配节点</a>特性，资源不足的判定将同时在本地 cgroup 层次结构的终端用户 pod 部分和根节点做出。这个 <a href="/docs/tasks/administer-cluster/out-of-resource/memory-available.sh">脚本</a>复现了与 <code>kubelet</code> 计算 <code>memory.available</code> 相同的步骤。<code>kubelet</code>将<code>inactive_file</code>（意即活动 LRU 列表上基于文件后端的内存字节数）从计算中排除，因为它假设内存在出现压力时将被回收。</p>

<p><code>kubelet</code> 只支持两种文件系统分区。</p>

<ol>
<li><code>nodefs</code> 文件系统，kubelet 将其用于卷和守护程序日志等。</li>
<li><code>imagefs</code> 文件系统，容器运行时用于保存镜像和容器可写层。</li>
</ol>

<p><code>imagefs</code>可选。<code>kubelet</code>使用 cAdvisor 自动发现这些文件系统。<code>kubelet</code>不关心其它文件系统。当前不支持配置任何其它类型。例如，在专用<code>文件系统</code>中存储卷和日志是不可以的。</p>

<p>在将来的发布中，<code>kubelet</code>将废除当前存在的 <a href="/docs/concepts/cluster-administration/kubelet-garbage-collection/">垃圾回收</a> 机制，这种机制目前支持将驱逐操作作为对磁盘压力的响应。</p>

<!--
### Eviction Thresholds

The `kubelet` supports the ability to specify eviction thresholds that trigger the `kubelet` to reclaim resources.

Each threshold has the following form:

`[eviction-signal][operator][quantity]`

where:

* `eviction-signal` is an eviction signal token as defined in the previous table.
* `operator` is the desired relational operator, such as `<` (less than).
* `quantity` is the eviction threshold quantity, such as `1Gi`. These tokens must
match the quantity representation used by Kubernetes. An eviction threshold can also
be expressed as a percentage using the `%` token.

For example, if a node has `10Gi` of total memory and you want trigger eviction if
the available memory falls below `1Gi`, you can define the eviction threshold as
either `memory.available<10%` or `memory.available<1Gi`. You cannot use both.
-->

<h3 id="驱逐阈值">驱逐阈值</h3>

<p><code>kubelet</code>支持指定驱逐阈值，用于触发 <code>kubelet</code> 回收资源。</p>

<p>每个阈值形式如下：</p>

<p><code>[eviction-signal][operator][quantity]</code></p>

<ul>
<li>合法的 <code>eviction-signal</code> 标志如上所示。</li>
<li><code>operator</code> 是所需的关系运算符，例如 <code>&lt;</code>。</li>
<li><code>quantity</code> 是驱逐阈值值标志，例如 <code>1Gi</code>。合法的标志必须匹配 Kubernetes 使用的数量表示。驱逐阈值也可以使用 <code>%</code> 标记表示百分比。</li>
</ul>

<p>举例说明，如果一个节点有 <code>10Gi</code> 内存，希望在可用内存下降到 <code>1Gi</code> 以下时引起驱逐操作，则驱逐阈值可以使用下面任意一种方式指定（但不是两者同时）。</p>

<ul>
<li><code>memory.available&lt;10%</code></li>
<li><code>memory.available&lt;1Gi</code></li>
</ul>

<!--
#### Soft Eviction Thresholds

A soft eviction threshold pairs an eviction threshold with a required
administrator-specified grace period. No action is taken by the `kubelet`
to reclaim resources associated with the eviction signal until that grace
period has been exceeded. If no grace period is provided, the `kubelet`
returns an error on startup.

In addition, if a soft eviction threshold has been met, an operator can
specify a maximum allowed Pod termination grace period to use when evicting
pods from the node. If specified, the `kubelet` uses the lesser value among
the `pod.Spec.TerminationGracePeriodSeconds` and the max allowed grace period.
If not specified, the `kubelet` kills Pods immediately with no graceful
termination.

To configure soft eviction thresholds, the following flags are supported:

* `eviction-soft` describes a set of eviction thresholds (e.g. `memory.available<1.5Gi`) that if met over a
corresponding grace period would trigger a Pod eviction.
* `eviction-soft-grace-period` describes a set of eviction grace periods (e.g. `memory.available=1m30s`) that
correspond to how long a soft eviction threshold must hold before triggering a Pod eviction.
* `eviction-max-pod-grace-period` describes the maximum allowed grace period (in seconds) to use when terminating
pods in response to a soft eviction threshold being met.
-->

<h4 id="软驱逐阈值">软驱逐阈值</h4>

<p>软驱逐阈值使用一对由驱逐阈值和管理员必须指定的宽限期组成的配置对。在超过宽限期前，<code>kubelet</code>不会采取任何动作回收和驱逐信号关联的资源。如果没有提供宽限期，<code>kubelet</code>启动时将报错。</p>

<p>此外，如果达到了软驱逐阈值，操作员可以指定从节点驱逐 pod 时，在宽限期内允许结束的 pod 的最大数量。如果指定了 <code>pod.Spec.TerminationGracePeriodSeconds</code> 值，<code>kubelet</code>将使用它和宽限期二者中较小的一个。如果没有指定，<code>kubelet</code>将立即终止 pod，而不会优雅结束它们。</p>

<p>软驱逐阈值的配置支持下列标记：</p>

<ul>
<li><code>eviction-soft</code> 描述了驱逐阈值的集合（例如 <code>memory.available&lt;1.5Gi</code>），如果在宽限期之外满足条件将触发 pod 驱逐。</li>
<li><code>eviction-soft-grace-period</code> 描述了驱逐宽限期的集合（例如 <code>memory.available=1m30s</code>），对应于在驱逐 pod 前软驱逐阈值应该被控制的时长。</li>
<li><code>eviction-max-pod-grace-period</code> 描述了当满足软驱逐阈值并终止 pod 时允许的最大宽限期值（秒数）。</li>
</ul>

<!--
#### Hard Eviction Thresholds

A hard eviction threshold has no grace period, and if observed, the `kubelet`
will take immediate action to reclaim the associated starved resource. If a
hard eviction threshold is met, the `kubelet` kills the Pod immediately
with no graceful termination.

To configure hard eviction thresholds, the following flag is supported:

* `eviction-hard` describes a set of eviction thresholds (e.g. `memory.available<1Gi`) that if met
would trigger a Pod eviction.

The `kubelet` has the following default hard eviction threshold:

* `memory.available<100Mi`
* `nodefs.available<10%`
* `nodefs.inodesFree<5%`
* `imagefs.available<15%`
-->

<h4 id="硬驱逐阈值">硬驱逐阈值</h4>

<p>硬驱逐阈值没有宽限期，一旦察觉，<code>kubelet</code>将立即采取行动回收关联的短缺资源。如果满足硬驱逐阈值，<code>kubelet</code>将立即结束 pod 而不是优雅终止。</p>

<p>硬驱逐阈值的配置支持下列标记：</p>

<ul>
<li><code>eviction-hard</code> 描述了驱逐阈值的集合（例如 <code>memory.available&lt;1Gi</code>），如果满足条件将触发 pod 驱逐。</li>
</ul>

<p><code>kubelet</code> 有如下所示的默认硬驱逐阈值：</p>

<ul>
<li><code>memory.available&lt;100Mi</code></li>
<li><code>nodefs.available&lt;10%</code></li>
<li><code>nodefs.inodesFree&lt;5%</code></li>
<li><code>imagefs.available&lt;15%</code></li>
</ul>

<!--
### Eviction Monitoring Interval

The `kubelet` evaluates eviction thresholds per its configured housekeeping interval.

* `housekeeping-interval` is the interval between container housekeepings.
-->

<h3 id="驱逐监控时间间隔">驱逐监控时间间隔</h3>

<p><code>kubelet</code> 根据其配置的整理时间间隔计算驱逐阈值。</p>

<ul>
<li><code>housekeeping-interval</code> 是容器管理时间间隔。</li>
</ul>

<!--
### Node Conditions

The `kubelet` maps one or more eviction signals to a corresponding node condition.

If a hard eviction threshold has been met, or a soft eviction threshold has been met
independent of its associated grace period, the `kubelet` reports a condition that
reflects the node is under pressure.

The following node conditions are defined that correspond to the specified eviction signal.

| Node Condition | Eviction Signal  | Description                                                      |
|-------------------------|-------------------------------|--------------------------------------------|
| `MemoryPressure` | `memory.available` | Available memory on the node has satisfied an eviction threshold |
| `DiskPressure` | `nodefs.available`, `nodefs.inodesFree`, `imagefs.available`, or `imagefs.inodesFree` | Available disk space and inodes on either the node's root filesystem or image filesystem has satisfied an eviction threshold |

The `kubelet` continues to report node status updates at the frequency specified by
`--node-status-update-frequency` which defaults to `10s`.
-->

<h3 id="节点状态">节点状态</h3>

<p><code>kubelet</code> 会将一个或多个驱逐信号映射到对应的节点状态。</p>

<p>如果满足硬驱逐阈值，或者满足独立于其关联宽限期的软驱逐阈值时，<code>kubelet</code>将报告节点处于压力下的状态。</p>

<p>下列节点状态根据相应的驱逐信号定义。</p>

<table>
<thead>
<tr>
<th>节点状态</th>
<th>驱逐信号</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>MemoryPressure</code></td>
<td><code>memory.available</code></td>
<td>Available memory on the node has satisfied an eviction threshold</td>
</tr>

<tr>
<td><code>DiskPressure</code></td>
<td><code>nodefs.available</code>, <code>nodefs.inodesFree</code>, <code>imagefs.available</code>, or <code>imagefs.inodesFree</code></td>
<td>Available disk space and inodes on either the node&rsquo;s root filesystem or image filesystem has satisfied an eviction threshold</td>
</tr>
</tbody>
</table>

<p><code>kubelet</code> 将以 <code>--node-status-update-frequency</code> 指定的频率连续报告节点状态更新，其默认值为 <code>10s</code>。</p>

<!--
### Oscillation of node conditions

If a node is oscillating above and below a soft eviction threshold, but not exceeding
its associated grace period, it would cause the corresponding node condition to
constantly oscillate between true and false, and could cause poor scheduling decisions
as a consequence.

To protect against this oscillation, the following flag is defined to control how
long the `kubelet` must wait before transitioning out of a pressure condition.

* `eviction-pressure-transition-period` is the duration for which the `kubelet` has
to wait before transitioning out of an eviction pressure condition.

The `kubelet` would ensure that it has not observed an eviction threshold being met
for the specified pressure condition for the period specified before toggling the
condition back to `false`.
-->

<h3 id="节点状态振荡">节点状态振荡</h3>

<p>如果节点在软驱逐阈值的上下振荡，但没有超过关联的宽限期时，将引起对应节点的状态持续在 true 和 false 间跳变，并导致不好的调度结果。</p>

<p>为了防止这种振荡，可以定义下面的标志，用于控制 <code>kubelet</code> 从压力状态中退出之前必须等待的时间。</p>

<ul>
<li><code>eviction-pressure-transition-period</code> 是 <code>kubelet</code> 从压力状态中退出之前必须等待的时长。</li>
</ul>

<p><code>kubelet</code> 将确保在设定的时间段内没有发现和指定压力条件相对应的驱逐阈值被满足时，才会将状态变回 <code>false</code>。</p>

<!--
### Reclaiming node level resources

If an eviction threshold has been met and the grace period has passed,
the `kubelet` initiates the process of reclaiming the pressured resource
until it has observed the signal has gone below its defined threshold.

The `kubelet` attempts to reclaim node level resources prior to evicting end-user Pods. If
disk pressure is observed, the `kubelet` reclaims node level resources differently if the
machine has a dedicated `imagefs` configured for the container runtime.
-->

<h3 id="回收节点层级资源">回收节点层级资源</h3>

<p>如果满足驱逐阈值并超过了宽限期，<code>kubelet</code>将启动回收压力资源的过程，直到它发现低于设定阈值的信号为止。</p>

<p><code>kubelet</code>将尝试在驱逐终端用户 pod 前回收节点层级资源。发现磁盘压力时，如果节点针对容器运行时配置有独占的 <code>imagefs</code>，<code>kubelet</code>回收节点层级资源的方式将会不同。</p>

<!--
#### With `imagefs`

If `nodefs` filesystem has met eviction thresholds, `kubelet` frees up disk space by deleting the dead Pods and their containers.

If `imagefs` filesystem has met eviction thresholds, `kubelet` frees up disk space by deleting all unused images.

#### Without `imagefs`

If `nodefs` filesystem has met eviction thresholds, `kubelet` frees up disk space in the following order:

1. Delete dead Pods and their containers
2. Delete all unused images
-->

<h4 id="使用-imagefs">使用 <code>Imagefs</code></h4>

<p>如果 <code>nodefs</code> 文件系统满足驱逐阈值，<code>kubelet</code>通过驱逐 pod 及其容器来释放磁盘空间。</p>

<p>如果 <code>imagefs</code> 文件系统满足驱逐阈值，<code>kubelet</code>通过删除所有未使用的镜像来释放磁盘空间。</p>

<h4 id="未使用-imagefs">未使用 <code>Imagefs</code></h4>

<p>如果 <code>nodefs</code> 满足驱逐阈值，<code>kubelet</code>将以下面的顺序释放磁盘空间：</p>

<ol>
<li>删除停止运行的 pod/container</li>
<li>删除全部没有使用的镜像</li>
</ol>

<!--
### Evicting end-user Pods

If the `kubelet` is unable to reclaim sufficient resource on the node, `kubelet` begins evicting Pods.

The `kubelet` ranks Pods for eviction first by whether or not their usage of the starved resource exceeds requests,
then by [Priority](/docs/concepts/configuration/pod-priority-preemption/), and then by the consumption of the starved compute resource relative to the Pods' scheduling requests.

As a result, `kubelet` ranks and evicts Pods in the following order:

* `BestEffort` or `Burstable` Pods whose usage of a starved resource exceeds its request.
Such pods are ranked by Priority, and then usage above request.
* `Guaranteed` pods and `Burstable` pods whose usage is beneath requests are evicted last.
`Guaranteed` Pods are guaranteed only when requests and limits are specified for all
the containers and they are equal. Such pods are guaranteed to never be evicted because
of another Pod's resource consumption. If a system daemon (such as `kubelet`, `docker`,
and `journald`) is consuming more resources than were reserved via `system-reserved` or
`kube-reserved` allocations, and the node only has `Guaranteed` or `Burstable` Pods using
less than requests remaining, then the node must choose to evict such a Pod in order to
preserve node stability and to limit the impact of the unexpected consumption to other Pods.
In this case, it will choose to evict pods of Lowest Priority first.

If necessary, `kubelet` evicts Pods one at a time to reclaim disk when `DiskPressure`
is encountered. If the `kubelet` is responding to `inode` starvation, it reclaims
`inodes` by evicting Pods with the lowest quality of service first. If the `kubelet`
is responding to lack of available disk, it ranks Pods within a quality of service
that consumes the largest amount of disk and kill those first.
-->

<h3 id="驱逐最终用户的-pod">驱逐最终用户的 pod</h3>

<p>如果 <code>kubelet</code> 在节点上无法回收足够的资源，<code>kubelet</code>将开始驱逐 pod。</p>

<p><code>kubelet</code> 首先根据他们对短缺资源的使用是否超过请求来排除 pod 的驱逐行为，然后通过 <a href="/docs/concepts/configuration/pod-priority-preemption/">优先级</a>，然后通过相对于 pod 的调度请求消耗急需的计算资源。</p>

<p><code>kubelet</code> 按以下顺序对要驱逐的 pod 排名：</p>

<ul>
<li><code>BestEffort</code> 或 <code>Burstable</code>，其对短缺资源的使用超过了其请求，此类 pod 按优先级排序，然后使用高于请求。</li>
<li><code>Guaranteed</code> pod 和 <code>Burstable</code> pod，其使用率低于请求，最后被驱逐。<code>Guaranteed</code>pod 只有为所有的容器指定了要求和限制并且它们相等时才能得到保证。由于另一个 pod 的资源消耗，这些 pod 保证永远不会被驱逐。如果系统守护进程（例如 <code>kubelet</code>、<code>docker</code>、和 <code>journald</code>）消耗的资源多于通过 <code>system-reserved</code> 或 <code>kube-reserved</code> 分配保留的资源，并且该节点只有 <code>Guaranteed</code> 或 <code>Burstable</code> pod 使用少于剩余的请求，然后节点必须选择驱逐这样的 pod 以保持节点的稳定性并限制意外消耗对其他 pod 的影响。在这种情况下，它将首先驱逐优先级最低的 pod。</li>
</ul>

<p>必要时，<code>kubelet</code>会在遇到 <code>DiskPressure</code> 时驱逐一个 pod 来回收磁盘空间。如果 <code>kubelet</code> 响应 <code>inode</code> 短缺，它会首先驱逐服务质量最低的 pod 来回收 <code>inodes</code>。如果 <code>kubelet</code> 响应缺少可用磁盘，它会将 pod 排在服务质量范围内，该服务会消耗大量的磁盘并首先结束这些磁盘。</p>

<!--
#### With `imagefs`

If `nodefs` is triggering evictions, `kubelet` sorts Pods based on the usage on `nodefs`
- local volumes + logs of all its containers.

If `imagefs` is triggering evictions, `kubelet` sorts Pods based on the writable layer usage of all its containers.

#### Without `imagefs`

If `nodefs` is triggering evictions, `kubelet` sorts Pods based on their total disk usage
- local volumes + logs & writable layer of all its containers.
-->

<h4 id="使用-imagefs-1">使用 <code>imagefs</code></h4>

<p>如果是 <code>nodefs</code> 触发驱逐，<code>kubelet</code>将按 <code>nodefs</code> 用量 - 本地卷 + pod 的所有容器日志的总和对其排序。</p>

<p>如果是 <code>imagefs</code> 触发驱逐，<code>kubelet</code>将按 pod 所有可写层的用量对其进行排序。</p>

<h4 id="未使用-imagefs-1">未使用 <code>imagefs</code></h4>

<p>如果是 <code>nodefs</code> 触发驱逐，<code>kubelet</code>会根据磁盘的总使用情况对 pod 进行排序 - 本地卷 + 所有容器的日志及其可写层。</p>

<!--
### Minimum eviction reclaim

In certain scenarios, eviction of Pods could result in reclamation of small amount of resources. This can result in
`kubelet` hitting eviction thresholds in repeated successions. In addition to that, eviction of resources like `disk`,
 is time consuming.

To mitigate these issues, `kubelet` can have a per-resource `minimum-reclaim`. Whenever `kubelet` observes
resource pressure, `kubelet` attempts to reclaim at least `minimum-reclaim` amount of resource below
the configured eviction threshold.

For example, with the following configuration:

```
--eviction-hard=memory.available<500Mi,nodefs.available<1Gi,imagefs.available<100Gi
--eviction-minimum-reclaim="memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi"`
```

If an eviction threshold is triggered for `memory.available`, the `kubelet` works to ensure
that `memory.available` is at least `500Mi`. For `nodefs.available`, the `kubelet` works
to ensure that `nodefs.available` is at least `1.5Gi`, and for `imagefs.available` it
works to ensure that `imagefs.available` is at least `102Gi` before no longer reporting pressure
on their associated resources.

The default `eviction-minimum-reclaim` is `0` for all resources.
-->

<h3 id="最小驱逐回收">最小驱逐回收</h3>

<p>在某些场景，驱逐 pod 会导致回收少量资源。这将导致 <code>kubelet</code> 反复碰到驱逐阈值。除此之外，对如 <code>disk</code> 这类资源的驱逐时比较耗时的。</p>

<p>为了减少这类问题，<code>kubelet</code>可以为每个资源配置一个 <code>minimum-reclaim</code>。当 <code>kubelet</code> 发现资源压力时，<code>kubelet</code>将尝试至少回收驱逐阈值之下 <code>minimum-reclaim</code> 数量的资源。</p>

<p>例如使用下面的配置：</p>

<pre><code>--eviction-hard=memory.available&lt;500Mi,nodefs.available&lt;1Gi,imagefs.available&lt;100Gi
--eviction-minimum-reclaim=&quot;memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi&quot;`
</code></pre>

<p>如果 <code>memory.available</code> 驱逐阈值被触发，<code>kubelet</code>将保证 <code>memory.available</code> 至少为 <code>500Mi</code>。对于 <code>nodefs.available</code>，<code>kubelet</code>将保证 <code>nodefs.available</code> 至少为 <code>1.5Gi</code>。对于 <code>imagefs.available</code>，<code>kubelet</code>将保证 <code>imagefs.available</code> 至少为 <code>102Gi</code>，直到不再有相关资源报告压力为止。</p>

<p>所有资源的默认 <code>eviction-minimum-reclaim</code> 值为 <code>0</code>。</p>

<!--
### Scheduler

The node reports a condition when a compute resource is under pressure. The
scheduler views that condition as a signal to dissuade placing additional
pods on the node.

| Node Condition    | Scheduler Behavior                               |
| ---------------- | ------------------------------------------------ |
| `MemoryPressure` | No new `BestEffort` Pods are scheduled to the node. |
| `DiskPressure` | No new Pods are scheduled to the node. |
-->

<h3 id="调度器">调度器</h3>

<p>当资源处于压力之下时，节点将报告状态。调度器将那种状态视为一种信号，阻止更多 pod 调度到这个节点上。</p>

<table>
<thead>
<tr>
<th>节点状态</th>
<th>调度器行为</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>MemoryPressure</code></td>
<td>No new <code>BestEffort</code> Pods are scheduled to the node.</td>
</tr>

<tr>
<td><code>DiskPressure</code></td>
<td>No new Pods are scheduled to the node.</td>
</tr>
</tbody>
</table>

<!--
## Node OOM Behavior

If the node experiences a system OOM (out of memory) event prior to the `kubelet` is able to reclaim memory,
the node depends on the [oom_killer](https://lwn.net/Articles/391222/) to respond.

The `kubelet` sets a `oom_score_adj` value for each container based on the quality of service for the Pod.

| Quality of Service | oom_score_adj |
|----------------------------|-----------------------------------------------------------------------|
| `Guaranteed` | -998 |
| `BestEffort` | 1000 |
| `Burstable` | min(max(2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) |

If the `kubelet` is unable to reclaim memory prior to a node experiencing system OOM, the `oom_killer` calculates
an `oom_score` based on the percentage of memory it's using on the node, and then add the `oom_score_adj` to get an
effective `oom_score` for the container, and then kills the container with the highest score.

The intended behavior should be that containers with the lowest quality of service that
are consuming the largest amount of memory relative to the scheduling request should be killed first in order
to reclaim memory.

Unlike Pod eviction, if a Pod container is OOM killed, it may be restarted by the `kubelet` based on its `RestartPolicy`.
-->

<h2 id="节点-oom-行为">节点 OOM 行为</h2>

<p>如果节点在 <code>kubelet</code> 回收内存之前经历了系统 OOM（内存不足）事件，它将基于 <a href="https://lwn.net/Articles/391222/" target="_blank">oom-killer</a> 做出响应。</p>

<p><code>kubelet</code> 基于 pod 的 service 质量为每个容器设置一个 <code>oom_score_adj</code> 值。</p>

<table>
<thead>
<tr>
<th>Service 质量</th>
<th>oom_score_adj</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>Guaranteed</code></td>
<td>-998</td>
</tr>

<tr>
<td><code>BestEffort</code></td>
<td>1000</td>
</tr>

<tr>
<td><code>Burstable</code></td>
<td>min(max(2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999)</td>
</tr>
</tbody>
</table>

<p>如果 <code>kubelet</code> 在节点经历系统 OOM 之前无法回收内存，<code>oom_killer</code>将基于它在节点上使用的内存百分比算出一个 <code>oom_score</code>，并加上 <code>oom_score_adj</code> 得到容器的有效 <code>oom_score</code>，然后结束得分最高的容器。</p>

<p>预期的行为应该是拥有最低 service 质量并消耗和调度请求相关内存量最多的容器第一个被结束，以回收内存。</p>

<p>和 pod 驱逐不同，如果一个 pod 的容器是被 OOM 结束的，基于其 <code>RestartPolicy</code>，它可能会被 <code>kubelet</code> 重新启动。</p>

<!--
## Best Practices

The following sections describe best practices for out of resource handling.

### Schedulable resources and eviction policies

Consider the following scenario:

* Node memory capacity: `10Gi`
* Operator wants to reserve 10% of memory capacity for system daemons (kernel, `kubelet`, etc.)
* Operator wants to evict Pods at 95% memory utilization to reduce incidence of system OOM.

To facilitate this scenario, the `kubelet` would be launched as follows:

```
--eviction-hard=memory.available<500Mi
--system-reserved=memory=1.5Gi
```

Implicit in this configuration is the understanding that "System reserved" should include the amount of memory
covered by the eviction threshold.

To reach that capacity, either some Pod is using more than its request, or the system is using more than `1.5Gi - 500Mi = 1Gi`.

This configuration ensures that the scheduler does not place Pods on a node that immediately induce memory pressure
and trigger eviction assuming those Pods use less than their configured request.
-->

<h2 id="最佳实践">最佳实践</h2>

<p>以下部分描述了资源外处理的最佳实践。</p>

<h3 id="可调度资源和驱逐策略">可调度资源和驱逐策略</h3>

<p>考虑以下场景：</p>

<ul>
<li>节点内存容量：<code>10Gi</code></li>
<li>操作员希望为系统守护进程保留 10% 内存容量（内核、<code>kubelet</code>等）。</li>
<li>操作员希望在内存用量达到 95% 时驱逐 pod，以减少对系统的冲击并防止系统 OOM 的发生。</li>
</ul>

<p>为了促成这个场景，<code>kubelet</code>将像下面这样启动：</p>

<pre><code>--eviction-hard=memory.available&lt;500Mi
--system-reserved=memory=1.5Gi
</code></pre>

<p>这个配置的暗示是理解系统保留应该包含被驱逐阈值覆盖的内存数量。</p>

<p>要达到这个容量，要么某些 pod 使用了超过它们请求的资源，要么系统使用的内存超过 <code>1.5Gi - 500Mi = 1Gi</code>。</p>

<p>这个配置将保证在 pod 使用量都不超过它们配置的请求值时，如果可能立即引起内存压力并触发驱逐时，调度器不会将 pod 放到这个节点上。</p>

<!--
### DaemonSet

It is never desired for `kubelet` to evict a `DaemonSet` Pod, since the Pod is
immediately recreated and rescheduled back to the same node.

At the moment, the `kubelet` has no ability to distinguish a Pod created
from `DaemonSet` versus any other object. If/when that information is
available, the `kubelet` could pro-actively filter those Pods from the
candidate set of Pods provided to the eviction strategy.

In general, it is strongly recommended that `DaemonSet` not
create `BestEffort` Pods to avoid being identified as a candidate Pod
for eviction. Instead `DaemonSet` should ideally launch `Guaranteed` Pods.
-->

<h3 id="daemonset">DaemonSet</h3>

<p>我们永远都不希望 <code>kubelet</code> 驱逐一个从 <code>DaemonSet</code> 派生的 pod，因为这个 pod 将立即被重建并调度回相同的节点。</p>

<p>目前，<code>kubelet</code>没有办法区分一个 pod 是由 <code>DaemonSet</code> 还是其他对象创建。如果/当这个信息可用时，<code>kubelet</code>可能会预先将这些 pod 从提供给驱逐策略的候选集合中过滤掉。</p>

<p>总之，强烈推荐 <code>DaemonSet</code> 不要创建 <code>BestEffort</code> 的 pod，防止其被识别为驱逐的候选 pod。相反，理想情况下 <code>DaemonSet</code> 应该启动 <code>Guaranteed</code> 的 pod。</p>

<!--
## Deprecation of existing feature flags to reclaim disk

`kubelet` has been freeing up disk space on demand to keep the node stable.

As disk based eviction matures, the following `kubelet` flags are marked for deprecation
in favor of the simpler configuration supported around eviction.

| Existing Flag | New Flag |
| ------------- | -------- |
| `--image-gc-high-threshold` | `--eviction-hard` or `eviction-soft` |
| `--image-gc-low-threshold` | `--eviction-minimum-reclaim` |
| `--maximum-dead-containers` | deprecated |
| `--maximum-dead-containers-per-container` | deprecated |
| `--minimum-container-ttl-duration` | deprecated |
| `--low-diskspace-threshold-mb` | `--eviction-hard` or `eviction-soft` |
| `--outofdisk-transition-frequency` | `--eviction-pressure-transition-period` |
-->

<h2 id="弃用现有特性标签以回收磁盘">弃用现有特性标签以回收磁盘</h2>

<p><code>kubelet</code> 已经按需求清空了磁盘空间以保证节点稳定性。</p>

<p>当磁盘驱逐成熟时，下面的 <code>kubelet</code> 标志将被标记为废弃的，以简化支持驱逐的配置。</p>

<table>
<thead>
<tr>
<th>现有标签</th>
<th>新标签</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>--image-gc-high-threshold</code></td>
<td><code>--eviction-hard</code> or <code>eviction-soft</code></td>
</tr>

<tr>
<td><code>--image-gc-low-threshold</code></td>
<td><code>--eviction-minimum-reclaim</code></td>
</tr>

<tr>
<td><code>--maximum-dead-containers</code></td>
<td>deprecated</td>
</tr>

<tr>
<td><code>--maximum-dead-containers-per-container</code></td>
<td>deprecated</td>
</tr>

<tr>
<td><code>--minimum-container-ttl-duration</code></td>
<td>deprecated</td>
</tr>

<tr>
<td><code>--low-diskspace-threshold-mb</code></td>
<td><code>--eviction-hard</code> or <code>eviction-soft</code></td>
</tr>

<tr>
<td><code>--outofdisk-transition-frequency</code></td>
<td><code>--eviction-pressure-transition-period</code></td>
</tr>
</tbody>
</table>

<!--
## Known issues

The following sections describe known issues related to out of resource handling.

### kubelet may not observe memory pressure right away

The `kubelet` currently polls `cAdvisor` to collect memory usage stats at a regular interval. If memory usage
increases within that window rapidly, the `kubelet` may not observe `MemoryPressure` fast enough, and the `OOMKiller`
will still be invoked. We intend to integrate with the `memcg` notification API in a future release to reduce this
latency, and instead have the kernel tell us when a threshold has been crossed immediately.

If you are not trying to achieve extreme utilization, but a sensible measure of overcommit, a viable workaround for
this issue is to set eviction thresholds at approximately 75% capacity. This increases the ability of this feature
to prevent system OOMs, and promote eviction of workloads so cluster state can rebalance.
-->

<h2 id="已知问题">已知问题</h2>

<p>以下部分描述了与资源外处理有关的已知问题。</p>

<h3 id="kubelet-可能无法立即发现内存压力">kubelet 可能无法立即发现内存压力</h3>

<p><code>kubelet</code>当前通过以固定的时间间隔轮询 <code>cAdvisor</code> 来收集内存使用数据。如果内存使用在那个时间窗口内迅速增长，<code>kubelet</code>可能不能足够快的发现 <code>MemoryPressure</code>，<code>OOMKiller</code>将不会被调用。我们准备在将来的发行版本中通过集成 <code>memcg</code> 通知 API 来减小这种延迟。当超过阈值时，内核将立即告诉我们。</p>

<p>如果您想处理可察觉的超量使用而不要求极端精准，可以设置驱逐阈值为大约 75% 容量作为这个问题的变通手段。这将增强这个特性的能力，防止系统 OOM，并提升负载卸载能力，以再次平衡集群状态。</p>

<!--
### kubelet may evict more Pods than needed

The Pod eviction may evict more Pods than needed due to stats collection timing gap. This can be mitigated by adding
the ability to get root container stats on an on-demand basis [(https://github.com/google/cadvisor/issues/1247)](https://github.com/google/cadvisor/issues/1247) in the future.
-->

<h3 id="kubelet-可能会驱逐超过需求数量的-pod">kubelet 可能会驱逐超过需求数量的 pod</h3>

<p>由于状态采集的时间差，驱逐操作可能驱逐比所需的更多的 pod。将来可通过添加从根容器获取所需状态的能力 <a href="https://github.com/google/cadvisor/issues/1247" target="_blank">https://github.com/google/cadvisor/issues/1247</a> 来减缓这种状况。</p>



<!--
---
reviewers:
- derekwaynecarr
- vishh
- timstclair
title: Configure Out Of Resource Handling
content_template: templates/concept
---
-->













    
            
  <h2>反馈</h2>
  <p class="feedback--prompt">此页是否对您有帮助？ </p>
  <button class="button feedback--yes">是</button>
  <button class="button feedback--no">否</button>
  <p class="feedback--response feedback--response__hidden">
    感谢反馈。如果您有一个关于如何使用 Kubernetes 的特定的、需要答案的问题，可以访问
    <a target="_blank" rel="noopener"
      href="https://stackoverflow.com/questions/tagged/kubernetes">
      Stack Overflow</a>.
    在 GitHub 仓库上登记新的问题
    <a class="feedback--link" target="_blank" rel="noopener"
      href="https://github.com/kubernetes/website/issues/new?title=Issue%20with%20k8s.io">
      报告问题</a>
    或者
    <a class="feedback--link" target="_blank" rel="noopener"
      href="https://github.com/kubernetes/website/issues/new?title=Improvement%20for%20k8s.io">
      提出改进建议</a>.
  </p>
  <script>
    const yes = document.querySelector('.feedback--yes');
    const no = document.querySelector('.feedback--no');
    document.querySelectorAll('.feedback--link').forEach(link => {
      link.href = link.href + window.location.pathname;
    });
    const sendFeedback = (value) => {
      if (!gtag) { console.log('!gtag'); }
      gtag('event', 'click', {
        'event_category': 'Helpful',
        'event_label': window.location.pathname,
        value
      });
    };
    const disableButtons = () => {
      yes.disabled = true;
      yes.classList.add('feedback--button__disabled');
      no.disabled = true;
      no.classList.add('feedback--button__disabled');
    };
    yes.addEventListener('click', () => {
      sendFeedback(1);
      disableButtons();
      document.querySelector('.feedback--response').classList.remove('feedback--response__hidden');
    });
    no.addEventListener('click', () => {
      sendFeedback(0);
      disableButtons();
      document.querySelector('.feedback--response').classList.remove('feedback--response__hidden');
    });
  </script>


    
            <div id="pre-footer"> 
  <hr />

  <div class="issue-button-container">
    <p><a href=""><img src="https://kubernetes-site.appspot.com/UA-36037335-10/GitHub/docs/tasks/administer-cluster/out-of-resource.md?pixel" alt="Analytics" /></a></p>
    
    
    <script type="text/javascript">
    PDRTJS_settings_8345992 = {
    "id" : "8345992",
    "unique_id" : "\/zh\/docs\/tasks\/administer-cluster\/out-of-resource\/",
    "title" : "配置资源不足时的处理方式",
    "permalink" : "https:\/\/kubernetes.io\/zh\/docs\/tasks\/administer-cluster\/out-of-resource\/"
    };
    (function(d,c,j){if(!document.getElementById(j)){var pd=d.createElement(c),s;pd.id=j;pd.src=('https:'==document.location.protocol)?'https://polldaddy.com/js/rating/rating.js':'http://i0.poll.fm/js/rating/rating.js';s=document.getElementsByTagName(c)[0];s.parentNode.insertBefore(pd,s);}}(document,'script','pd-rating-js'));
    </script>
    <a href="" onclick="window.open('https://github.com/kubernetes/website/issues/new?template=bug-report.md&title=Issue%20with%20' +
    'k8s.io'+window.location.pathname)" class="button issue">报告 GitHub 问题</a>
    
    
    
    <a href="https://github.com/kubernetes/website/edit/master/content/zh/docs/tasks/administer-cluster/out-of-resource.md" class="button issue">修改本页面</a>
    
  </div>
  

  <div id="lastedit" class="lastedit issue-button-container">
    页面最后一次修改于 February 14, 2020 at 10:22 AM PST 由：
    <a href="https://github.com/kubernetes/website/commit/37137dadaf2acd80c9355bacb1597ffff4731956/">fix format error (#19118)</a> (<a href="https://github.com/kubernetes/website/commits/master/content/en/docs/tasks/administer-cluster/out-of-resource.md">页面历史</a>)
  </div>
  
</div>

          </div>
        </section>
    </main>
		<footer>
    <div class="light-text main-section">
        <nav>
            
            
            
            <a href="/zh/docs/home/">主页</a>
            
            <a href="/zh/blog/">博客</a>
            
            
            
            <a href="/zh/partners/">合作伙伴</a>
            
            <a href="/zh/community/">社区</a>
            
            <a href="/zh/case-studies/">案例分析</a>
            
        </nav>
        <div class="social" role="region" aria-label="Social hyperlinks">
            <div>
                <a href="https://twitter.com/kubernetesio" class="twitter"><span>Twitter</span></a>
                <a href="https://github.com/kubernetes/kubernetes" class="github"><span>GitHub</span></a>
                <a href="https://slack.k8s.io/" class="slack"><span>Slack</span></a>
            </div>
            <div>
                <a href="https://stackoverflow.com/questions/tagged/kubernetes" class="stack-overflow"><span>Stack Overflow</span></a>
                <a href="https://www.youtube.com/kubernetescommunity" class="youtube"><span>YouTube</span></a>
                <a href="https://discuss.kubernetes.io" class="mailing-list"><span>论坛</span></a>
                <a href="https://calendar.google.com/calendar/embed?src=nt2tcnbtbied3l6gi2h29slvc0%40group.calendar.google.com" class="calendar"><span>事件日历</span></a>
            </div>
            <div>
                
                <a href="https://git.k8s.io/community/contributors/guide" class="button">贡献</a>
            </div>
        </div>
        <div class="miceType center">
            &copy; 2023 The Kubernetes 作者 | 文档发布基于 <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a> 授权许可</a>
        </div>
        <div class="miceType center">
            Copyright &copy; 2023 Linux 基金会&reg;。保留所有权利。Linux 基金会已注册并使用商标。如需了解 Linux 基金会的商标列表，请访问<a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">商标使用页面</a>
        </div>
        <div class="miceType center">
            ICP license: 京ICP备17074266号-3
        </div>
    </div>
</footer>

		<button class="flyout-button" onclick="kub.toggleToc()" aria-label="Toggle table of contents visibility"></button>

<script>

(function () {
    window.addEventListener('DOMContentLoaded', init)

        
        function init() {
            window.removeEventListener('DOMContentLoaded', init)
                hideNav()
        }

    function hideNav(toc){
        if (!toc) toc = document.querySelector('#docsToc')
        if (!toc) return
            var container = toc.querySelector('.container')

                
                if (container) {
                    if (container.childElementCount === 0 || toc.querySelectorAll('a.item').length === 1) {
                        toc.style.display = 'none'
                            document.getElementById('docsContent').style.width = '100%'
                    }
                } else {
                    requestAnimationFrame(function () {
                        hideNav(toc)
                    })
                }
    }
})();
</script>



    <script language="application/javascript">
      
      (function addHeadingLinks(){
        var article = document.getElementById('docsContent');
        var headings = article.querySelectorAll('h1, h2, h3, h4, h5, h6');
        headings.forEach(function(heading){
          if(heading.id){
            var a = document.createElement('a');
            a.innerHTML = heading.innerHTML;
            a.href = '#'+heading.id;
            a.classList.add('inpage_heading');
            heading.innerHTML = '';
            heading.appendChild(a);
          }
        });
      })();
    </script>
	</body>
</html>
